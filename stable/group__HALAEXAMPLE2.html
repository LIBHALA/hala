<!-- HTML header for doxygen 1.8.15-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>HALA: Handy Accelerated Linear Algebra v1.0: Example of GPU usage</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="hala.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
    <div class="doxygen">
            <a href="http://www.doxygen.org/index.html">
                <img class="footer" src="doxygen.png" alt="doxygen"/>
                </a> 1.8.13
    </div>
   <div id="projectname">HALA: Handy Accelerated Linear Algebra v1.0
   <!--         <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
 -->
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('group__HALAEXAMPLE2.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#files">Files</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">Example of GPU usage<div class="ingroups"><a class="el" href="group__HALAEXAMPLE.html">HALA Examples</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Collaboration diagram for Example of GPU usage:</div>
<div class="dyncontent">
<center><table><tr><td><img src="group__HALAEXAMPLE2.png" border="0" alt="" usemap="#group____HALAEXAMPLE2"/>
<map name="group____HALAEXAMPLE2" id="group____HALAEXAMPLE2">
<area shape="rect" id="node2" href="group__HALAEXAMPLE.html" title="HALA Examples" alt="" coords="5,5,124,32"/>
</map>
</td></tr></table></center>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="files"></a>
Files</h2></td></tr>
<tr class="memitem:example__gpu_8cpp"><td class="memItemLeft" align="right" valign="top">file &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="example__gpu_8cpp.html">example_gpu.cpp</a></td></tr>
<tr class="memdesc:example__gpu_8cpp"><td class="mdescLeft">&#160;</td><td class="mdescRight">Example of using the BLAS module of HALA. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga09994cea00d3618d3534c35ddc63757b"><td class="memTemplParams" colspan="2">template&lt;typename scalar_type &gt; </td></tr>
<tr class="memitem:ga09994cea00d3618d3534c35ddc63757b"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__HALAEXAMPLE2.html#ga09994cea00d3618d3534c35ddc63757b">discretize_pde</a> (int num_side, std::valarray&lt; int &gt; &amp;pntr, std::valarray&lt; int &gt; &amp;indx, std::valarray&lt; scalar_type &gt; &amp;vals, std::valarray&lt; scalar_type &gt; &amp;f)</td></tr>
<tr class="memdesc:ga09994cea00d3618d3534c35ddc63757b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the discretization of the PDE and the right hand side.  <a href="#ga09994cea00d3618d3534c35ddc63757b">More...</a><br /></td></tr>
<tr class="separator:ga09994cea00d3618d3534c35ddc63757b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad3706f9a2a499c7e64b7b7ee3ab81f50"><td class="memTemplParams" colspan="2"><a id="gad3706f9a2a499c7e64b7b7ee3ab81f50"></a>
template&lt;typename scalar_type &gt; </td></tr>
<tr class="memitem:gad3706f9a2a499c7e64b7b7ee3ab81f50"><td class="memTemplItemLeft" align="right" valign="top">scalar_type&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__HALAEXAMPLE2.html#gad3706f9a2a499c7e64b7b7ee3ab81f50">compute_l2_error</a> (std::valarray&lt; scalar_type &gt; &amp;u)</td></tr>
<tr class="memdesc:gad3706f9a2a499c7e64b7b7ee3ab81f50"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the l-2 error for the approximate solution <b>u</b> to the PDE. <br /></td></tr>
<tr class="separator:gad3706f9a2a499c7e64b7b7ee3ab81f50"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<dl class="section user"><dt>Example 2</dt><dd>Example 1 was a demonstration of the dense (BLAS) module of HALA that implemented a time-stepping scheme and a linear solver. The implementation used the optimized BLAS library on the CPU. Example 2 demonstrates the sparse capabilities of HALA by implementing a preconditioned conjugate-gradient method which can be used either on the CPU or GPU.</dd></dl>
<dl class="section user"><dt></dt><dd>The example is divided into several sections:<ul>
<li><a class="el" href="group__HALAEXAMPLE2.html#Example2Problem">Problem Setup</a></li>
<li><a class="el" href="group__HALAEXAMPLE2.html#Example2PCG">Preconditioned Conjugate Gradient method</a></li>
<li><a class="el" href="group__HALAEXAMPLE2.html#Example2PCGPU">GPU Implementation</a></li>
<li><a class="el" href="group__HALAEXAMPLE2.html#Example2PCMIX">Mixed Engine Overload</a></li>
<li><a class="el" href="group__HALAEXAMPLE2.html#Example2Solvers">Native HALA Solvers</a></li>
</ul>
</dd></dl>
<p><a class="anchor" id="Example2Problem"></a></p><dl class="section user"><dt>Problem Setup</dt><dd>Consider the elliptic partial differential equation \( - \Delta u = f \) in two-dimensions over the unit square with homogeneous Dirichlet boundary conditions. The forcing term is \( f(x, y) = 12 x^2 (y - y^3) + 6 y (x - x^4) \) which was chosen to yield an analytic solution is \( u(x, y) = (x - x^4)(y - y^3) \). We approximate the equation using a finite difference scheme using central difference for the second derivative. The intricacies of the equation and discretization are not in scope of HALA, it suffices to know that the two methods provided here <a class="el" href="group__HALAEXAMPLE2.html#ga09994cea00d3618d3534c35ddc63757b" title="Computes the discretization of the PDE and the right hand side. ">discretize_pde()</a> and <a class="el" href="group__HALAEXAMPLE2.html#gad3706f9a2a499c7e64b7b7ee3ab81f50" title="Computes the l-2 error for the approximate solution u to the PDE. ">compute_l2_error()</a> can be used to generate the sparse matrix and right-hand-side, and both work with std::valarray containers to demonstrate the generality of HALA, i.e., the HALA templates are not restricted to std::vector or other HALA specific containers.</dd></dl>
<p><a class="anchor" id="Example2PCG"></a></p><dl class="section user"><dt>Preconditioned Conjugate-Gradient method</dt><dd>Consider a sparse linear system of equations \( A u = f \), where <b>A</b> is the approximation to the Laplacian operator described in the previous section, <b>f</b> is the approximate forcing term and <b>u</b> is the approximate solution. The matrix <b>A</b> is symmetric-positive-definite and a good approach for solving such systems is the <a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method#:~:text=The%20preconditioned%20conjugate%20gradient%20method,-See%20also%3A%20Preconditioner&amp;text=The%20preconditioner%20matrix%20M%20has,change%20from%20iteration%20to%20iteration.&amp;text=An%20example%20of%20a%20commonly%20used%20preconditioner%20is%20the%20incomplete%20Cholesky%20factorization."><b>preconditioned</b> <b>conjugate-gradient</b> <b>method</b>. </a> The implementation is as follows:</dd></dl>
<div class="fragment"><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeP,  <span class="keyword">class</span> VectorLikeI, <span class="keyword">class</span> VectorLikeV, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeB&gt;</div><div class="line"><span class="keywordtype">int</span> <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(<span class="keywordtype">int</span> max_iter, <a class="code" href="group__HALACUSTOM.html#ga78609b70f45312e08e520b6ed736ff40">hala::get_precision_type&lt;VectorLikeV&gt;</a> stop_tolerance,</div><div class="line">              VectorLikeP <span class="keyword">const</span> &amp;pntr, VectorLikeI <span class="keyword">const</span> &amp;indx, VectorLikeV <span class="keyword">const</span> &amp;vals,</div><div class="line">              VectorLikeB <span class="keyword">const</span> &amp;b, VectorLikeX &amp;x){</div><div class="line">    assert( b.size() == x.size() );</div><div class="line"></div><div class="line">    <span class="keywordtype">int</span> num_rows = <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">hala::get_size_int</a>(pntr) - 1;</div><div class="line">    assert( b.size() == <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(num_rows) );</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> matrix = <a class="code" href="group__HALASPARSE.html#gab35ecfc9a918cf1dd863144202fdd14b">hala::make_sparse_matrix</a>(num_rows, pntr, indx, vals);</div><div class="line">    <span class="keyword">auto</span> ilu = <a class="code" href="group__HALASPARSEILU.html#gab7ebe9aba87ec87642ef9a8dea666e50">hala::make_ilu</a>(pntr, indx, vals, <span class="charliteral">&#39;N&#39;</span>);</div><div class="line"></div><div class="line">    <span class="keywordtype">size_t</span> buffer_size = std::max(</div><div class="line">                             <a class="code" href="group__HALAWAXSPARSE.html#ga108524f442e0748d505426150ce3df9a">ilu_buffer_size</a>(ilu, b, x, 1),</div><div class="line">                             <a class="code" href="group__HALASPARSEBLAS.html#gaefe666323135b3f97794ebe814ee822e">sparse_gemv_buffer_size</a>(matrix, <span class="charliteral">&#39;N&#39;</span>, 1.0, b, 0.0, x)</div><div class="line">                              );</div><div class="line">    <span class="keyword">auto</span> work_buffer = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">hala::new_vector</a>(x);</div><div class="line">    <a class="code" href="group__HALACUSTOM.html#ga957f659d97426f04b2060bceb9d90fee">hala::set_size</a>(buffer_size, work_buffer);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> r = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">hala::new_vector</a>(x);</div><div class="line">    <span class="keyword">auto</span> p = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">hala::new_vector</a>(x);</div><div class="line">    <span class="keyword">auto</span> Ap = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">hala::new_vector</a>(x);</div><div class="line">    <span class="keyword">auto</span> z  = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">hala::new_vector</a>(x);</div><div class="line"></div><div class="line">    <a class="code" href="group__HALABLAS1.html#ga199fd708ca4ff8b2c65b6ee47491b37d">hala::vcopy</a>(b, r);</div><div class="line">    <a class="code" href="group__HALASPARSEBLAS.html#ga224ea0b6952e5baeabfd0d4f2d581448">hala::sparse_gemv</a>(matrix, <span class="charliteral">&#39;N&#39;</span>, -1.0, x, 1.0, r, work_buffer);</div><div class="line">    <a class="code" href="group__HALAWAXSPARSE.html#gab396d1d160e3dd5bd3ba163b788b7f51">hala::ilu_apply</a>(ilu, r, z); <span class="comment">// in wikipedia notation, z = M^-1 r</span></div><div class="line"></div><div class="line">    <a class="code" href="group__HALABLAS1.html#ga199fd708ca4ff8b2c65b6ee47491b37d">hala::vcopy</a>(z, p);</div><div class="line">    <span class="keyword">auto</span> zr = <a class="code" href="group__HALABLAS1.html#ga55b878e5a1a05ef1c181a879edaa6528">hala::dot</a>(r, z);</div><div class="line"></div><div class="line">    <span class="keywordtype">int</span> iterations = 1; <span class="comment">// (above) applied one Ax with preconditioner</span></div><div class="line">    <span class="keywordtype">bool</span> iterate = <span class="keyword">true</span>;</div><div class="line"></div><div class="line">    <span class="keywordflow">while</span>(iterate){</div><div class="line">        <a class="code" href="group__HALASPARSEBLAS.html#ga224ea0b6952e5baeabfd0d4f2d581448">hala::sparse_gemv</a>(matrix, <span class="charliteral">&#39;N&#39;</span>, 1.0, p, 0.0, Ap, work_buffer);</div><div class="line">        iterations++;</div><div class="line"></div><div class="line">        <span class="keyword">auto</span> nzr = <a class="code" href="group__HALABLAS1.html#ga55b878e5a1a05ef1c181a879edaa6528">hala::dot</a>(Ap, p);</div><div class="line">        <span class="keyword">auto</span> alpha = zr / nzr;</div><div class="line"></div><div class="line">        <a class="code" href="group__HALABLAS1.html#ga0dff938a94c75c58427ede241c05429b">hala::axpy</a>( alpha,  p, x);</div><div class="line">        <a class="code" href="group__HALABLAS1.html#ga0dff938a94c75c58427ede241c05429b">hala::axpy</a>(-alpha, Ap, r);</div><div class="line"></div><div class="line">        iterate = not ((iterations &gt;= max_iter) or (<a class="code" href="group__HALABLAS1.html#ga48f8d9b686ef4a9cdb69897e3f22bbe5">hala::norm2</a>(r) &lt; stop_tolerance));</div><div class="line"></div><div class="line">        <span class="keywordflow">if</span> (iterate){ <span class="comment">// skip this part of done already</span></div><div class="line">            <a class="code" href="group__HALAWAXSPARSE.html#gab396d1d160e3dd5bd3ba163b788b7f51">hala::ilu_apply</a>(ilu, r, z, 1, work_buffer);</div><div class="line"></div><div class="line">            nzr = <a class="code" href="group__HALABLAS1.html#ga55b878e5a1a05ef1c181a879edaa6528">hala::dot</a>(r, z);</div><div class="line"></div><div class="line">            <a class="code" href="group__HALABLAS1.html#ga3d8f14a164c86b89abbb4e7bfbdca660">hala::scal</a>(nzr / zr, p);</div><div class="line">            <a class="code" href="group__HALABLAS1.html#ga0dff938a94c75c58427ede241c05429b">hala::axpy</a>(1.0, z, p);</div><div class="line"></div><div class="line">            zr = nzr;</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> iterations;</div><div class="line">}</div></div><!-- fragment --> <dl class="section user"><dt></dt><dd>The first thing to note is the generic <b>VectorLike</b> types for all the inputs, this is similar to the <a class="el" href="example__gauss__seidel_8cpp.html#aafcd9df6d4f5a468c02cfd2f8eebc6e5" title="[Example_01 gsb] ">solve_gauss_seidel_c()</a> method in <a class="el" href="group__HALAEXAMPLE1.html#Example1VarC">Example 1</a>. The full potential of this generality will become apparent later, for now we go over the section of the code in a step by step manner:<ul>
<li>as an iterative method, the CG algorithm takes as a stopping criteria either an error tolerance or a maximum number of iteration</li>
<li>couple of assertions check for proper sizes of the inputs, and note that HALA will perform additional type, e.g., <a class="el" href="group__HALASPARSE.html#gab35ecfc9a918cf1dd863144202fdd14b" title="Factory method to construct a sparse matrix. ">hala::make_sparse_matrix()</a> will check that the sizes of <b>vals</b> and <b>indx</b> match</li>
<li><b>x</b> is expected to be initialized with the zeroth iterate, e.g., zero vector</li>
<li>the sparse matrix triple is wrapped in a generic matrix struct and external workspace is allocated for the matrix-vector multiplication</li>
<li>the Incomplete Lower Upper factorization is computed with <a class="el" href="group__HALASPARSEILU.html#gab7ebe9aba87ec87642ef9a8dea666e50" title="Constructs an ILU preconditioner associated with a compute engine. ">hala::make_ilu()</a></li>
<li>temporary vectors are created with the <a class="el" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991" title="Returns a default vector with the default constructor. ">hala::new_vector()</a> command, which simply creates a default vector (e.g., std::vector) with scalar type matching x</li>
<li>the rest is direct translation of the algorithm into a series of BLAS operations, as well as <a class="el" href="group__HALASPARSEBLAS.html#ga224ea0b6952e5baeabfd0d4f2d581448" title="Sparse matrix vector multiplication. ">hala::sparse_gemv()</a> and application of the ILU preconditioner.</li>
</ul>
</dd></dl>
<dl class="section user"><dt></dt><dd>Using the two discretization methods, we solve the PDE using different number of points for the grid in the uniform discretization, and we plot the number of iterations, duration, degrees of freedom (problem size) and error. As expected, we observe convergence that is approximately linear in the degrees of freedom or quadratic in the size of the box discretization. Each time we assume that the initial guess is zero.</dd></dl>
<div class="fragment"><div class="line">    <span class="keywordtype">double</span> tolerance = 1.E-8;</div><div class="line">    <span class="keywordtype">int</span> max_iter = 100000; <span class="comment">// just pick a large number</span></div><div class="line">    <a class="code" href="structhala_1_1chronometer.html">hala::chronometer</a> meter;</div><div class="line"></div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;\nCompute using the CPU\n&quot;</span>;</div><div class="line">    cout &lt;&lt; setw(5) &lt;&lt; <span class="stringliteral">&quot;iter&quot;</span> &lt;&lt; setw(10) &lt;&lt; <span class="stringliteral">&quot;duration&quot;</span></div><div class="line">         &lt;&lt; setw(10) &lt;&lt; <span class="stringliteral">&quot;size&quot;</span> &lt;&lt; setw(15) &lt;&lt; <span class="stringliteral">&quot;error&quot;</span> &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div><div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> n : std::vector&lt;int&gt;{4, 8, 16, 32, 64, 128}){</div><div class="line"></div><div class="line">        std::valarray&lt;int&gt; pntr, indx;</div><div class="line">        std::valarray&lt;double&gt; vals, f;</div><div class="line"></div><div class="line">        <a class="code" href="group__HALAEXAMPLE2.html#ga09994cea00d3618d3534c35ddc63757b">discretize_pde</a>(n, pntr, indx, vals, f);</div><div class="line"></div><div class="line">        std::valarray&lt;double&gt; u(0.0, f.size());</div><div class="line"></div><div class="line">        meter.<a class="code" href="structhala_1_1chronometer.html#a4d8fa412a520e583eb0ecbb492d9fb3a">set_start</a>();</div><div class="line">        <span class="keywordtype">int</span> iter = <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(max_iter, tolerance, pntr, indx, vals, f, u);</div><div class="line">        <span class="keywordtype">long</span> <span class="keywordtype">long</span> duration = meter.<a class="code" href="structhala_1_1chronometer.html#a411ba500e2322086f19c0501c781ddc5">get_end</a>();</div><div class="line">        <span class="comment">// iter == max_iter means that the tolerance was not reached</span></div><div class="line">        assert( iter &lt; max_iter);</div><div class="line"></div><div class="line">        cout &lt;&lt; setw(5) &lt;&lt; iter &lt;&lt; setw(10) &lt;&lt; duration</div><div class="line">             &lt;&lt; setw(10) &lt;&lt; u.size() &lt;&lt; setw(15) &lt;&lt; <a class="code" href="group__HALAEXAMPLE2.html#gad3706f9a2a499c7e64b7b7ee3ab81f50">compute_l2_error</a>(u) &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div><div class="line">    }</div></div><!-- fragment --> <dl class="section user"><dt>Result</dt><dd><div class="fragment"><div class="line">iter  duration      size          error</div><div class="line">   9         0        16   1.000499e-03</div><div class="line">  14         0        64   3.092774e-04</div><div class="line">  23         0       256   8.669565e-05</div><div class="line">  41         4      1024   2.300756e-05</div><div class="line">  78        31      4096   5.930229e-06</div><div class="line"> 152       421     16384   1.505631e-06</div></div><!-- fragment --></dd></dl>
<p><a class="anchor" id="Example2PCGPU"></a></p><dl class="section user"><dt>GPU Implementation</dt><dd>The most expensive part of the CG method is the matrix vector product and the preconditioner and while the BLAS operations use the optimized backend library, the sparse operations are implementated native to HALA and are probably far from optimal. Sparse operations depend primarily to the memory speed and GPU (even consumer grade or gaming cards) have memory that is much faster than the main CPU one; and GPU frameworks such as CUDA and ROCm provide free accelerated libraries with the needed sparse implementations (ROCm is even open source). Thus, it is natural to seek a GPU accelerated version of the CG algorithm.</dd></dl>
<dl class="section user"><dt></dt><dd>The accelerated libraries provided by both CUDA and ROCm require GPU handle variables that indicate the current device in use and other implementation specific meta-data. In HALA, those are wrapped in a <a class="el" href="structhala_1_1gpu__engine.html" title="Core engine class, deals with handles and data transfer. ">hala::gpu_engine</a> object, and a straight forward way to port an algorithm to the GPU is to modify the code so that each call to HALA would take an engine variable, including the call to <a class="el" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459" title="[Example_02 pcg] ">solve_pcg()</a>. However, that requires modification to the code and will result in errors if even one call is missed; not to mention that the CPU implementations would also have to carry a <a class="el" href="structhala_1_1cpu__engine.html" title="The CPU Engine. ">hala::cpu_engine</a> object which is redundant.</dd></dl>
<dl class="section user"><dt></dt><dd>An alternative approach is to use the generality of the <b>VectorLike</b> classes and control the GPU-CPU selection by creating a special type of vectors, which bind a GPU or a CPU context to any user provided vector container. Thus, the original code requires no modifications, but a simple additional overload:</dd></dl>
<div class="fragment"><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">class </span>EngineType,</div><div class="line">         <span class="keyword">class </span>VectorLikeP,  <span class="keyword">class </span>VectorLikeI, <span class="keyword">class </span>VectorLikeV, <span class="keyword">class </span>VectorLikeX, <span class="keyword">class </span>VectorLikeB&gt;</div><div class="line"><span class="keywordtype">int</span> <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(EngineType <span class="keyword">const</span> &amp;engine,</div><div class="line">              <span class="keywordtype">int</span> max_iter, <a class="code" href="group__HALACUSTOM.html#ga78609b70f45312e08e520b6ed736ff40">hala::get_precision_type&lt;VectorLikeV&gt;</a> stop_tolerance,</div><div class="line">              VectorLikeP <span class="keyword">const</span> &amp;pntr, VectorLikeI <span class="keyword">const</span> &amp;indx, VectorLikeV <span class="keyword">const</span> &amp;vals,</div><div class="line">              VectorLikeB <span class="keyword">const</span> &amp;b, VectorLikeX &amp;x){</div><div class="line">    <span class="keyword">auto</span> bind_pntr = <a class="code" href="group__HALAWAXENGINED.html#gaf4ae7eba405e49b271e1279c2ec3f170">bind_engine_vector</a>(engine, pntr);</div><div class="line">    <span class="keyword">auto</span> bind_indx = <a class="code" href="group__HALAWAXENGINED.html#gaf4ae7eba405e49b271e1279c2ec3f170">bind_engine_vector</a>(engine, indx);</div><div class="line">    <span class="keyword">auto</span> bind_vals = <a class="code" href="group__HALAWAXENGINED.html#gaf4ae7eba405e49b271e1279c2ec3f170">bind_engine_vector</a>(engine, vals);</div><div class="line">    <span class="keyword">auto</span> bind_b = <a class="code" href="group__HALAWAXENGINED.html#gaf4ae7eba405e49b271e1279c2ec3f170">bind_engine_vector</a>(engine, b);</div><div class="line">    <span class="keyword">auto</span> bind_x = <a class="code" href="group__HALAWAXENGINED.html#gaf4ae7eba405e49b271e1279c2ec3f170">bind_engine_vector</a>(engine, x);</div><div class="line">    <span class="keywordflow">return</span> <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(max_iter, stop_tolerance,</div><div class="line">                     bind_pntr, bind_indx, bind_vals, bind_b, bind_x);</div><div class="line">}</div></div><!-- fragment --> <dl class="section user"><dt></dt><dd>The engine overload can be called with any of the three HALA engines, <a class="el" href="structhala_1_1cpu__engine.html" title="The CPU Engine. ">hala::cpu_engine</a>, <a class="el" href="structhala_1_1gpu__engine.html" title="Core engine class, deals with handles and data transfer. ">hala::gpu_engine</a> or hala::mixed_engine, and the original <a class="el" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459" title="[Example_02 pcg] ">solve_pcg()</a> will be instantiated in the appropriate context.</dd></dl>
<dl class="section user"><dt></dt><dd>The main method needs to be modified to provide the appropriate engine context and to move the date from the CPU over to the GPU side. Note that the entire block needs a pre-processor <b>ifndef</b> guard since the <a class="el" href="structhala_1_1gpu__engine.html" title="Core engine class, deals with handles and data transfer. ">hala::gpu_engine</a> and the load and unload methods are available only when a GPU backend is enabled.</dd></dl>
<div class="fragment"><div class="line">    <a class="code" href="structhala_1_1gpu__engine.html">hala::gpu_engine</a> egpu(0);</div><div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> n : std::vector&lt;int&gt;{4, 8, 16, 32, 64, 128}){</div><div class="line"></div><div class="line">        std::valarray&lt;int&gt; pntr, indx;</div><div class="line">        std::valarray&lt;double&gt; vals, f;</div><div class="line"></div><div class="line">        <a class="code" href="group__HALAEXAMPLE2.html#ga09994cea00d3618d3534c35ddc63757b">discretize_pde</a>(n, pntr, indx, vals, f);</div><div class="line">        std::valarray&lt;double&gt; u(0.0, f.size());</div><div class="line"></div><div class="line">        meter.<a class="code" href="structhala_1_1chronometer.html#a4d8fa412a520e583eb0ecbb492d9fb3a">set_start</a>();</div><div class="line">        <span class="keyword">auto</span> gpu_pntr = egpu.load(pntr);</div><div class="line">        <span class="keyword">auto</span> gpu_indx = egpu.load(indx);</div><div class="line">        <span class="keyword">auto</span> gpu_vals = egpu.load(vals);</div><div class="line">        <span class="keyword">auto</span> gpu_f = egpu.load(f);</div><div class="line">        <span class="keyword">auto</span> gpu_u = egpu.load(u);</div><div class="line">        <span class="keywordtype">int</span> iter = <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(egpu, max_iter, tolerance, gpu_pntr, gpu_indx, gpu_vals,</div><div class="line">                             gpu_f, gpu_u);</div><div class="line">        gpu_u.unload(u);</div><div class="line">        <span class="keywordtype">long</span> <span class="keywordtype">long</span> duration = meter.<a class="code" href="structhala_1_1chronometer.html#a411ba500e2322086f19c0501c781ddc5">get_end</a>();</div><div class="line"></div><div class="line">        std::valarray&lt;double&gt; cpu_u(0.0, f.size());</div><div class="line">        <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(<a class="code" href="structhala_1_1cpu__engine.html">hala::cpu_engine</a>(), max_iter, tolerance, pntr, indx, vals, f, cpu_u);</div><div class="line">        <a class="code" href="group__HALABLAS1.html#ga0dff938a94c75c58427ede241c05429b">hala::axpy</a>(-1.0, u, cpu_u);</div><div class="line">        assert(<a class="code" href="group__HALABLAS1.html#ga48f8d9b686ef4a9cdb69897e3f22bbe5">hala::norm2</a>(cpu_u) &lt; 1.E-11);</div><div class="line"></div><div class="line">        cout &lt;&lt; setw(5) &lt;&lt; iter &lt;&lt; setw(10) &lt;&lt; duration</div><div class="line">             &lt;&lt; setw(10) &lt;&lt; u.size() &lt;&lt; setw(15) &lt;&lt; <a class="code" href="group__HALAEXAMPLE2.html#gad3706f9a2a499c7e64b7b7ee3ab81f50">compute_l2_error</a>(u) &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div><div class="line">    }</div></div><!-- fragment --><p> <a class="anchor" id="Example2PCMIX"></a></p><dl class="section user"><dt>Mixed Engine Overload</dt><dd>The load and unload operations performed in the main are tedious and many applications follow a CPU bound workflow with only some operations offloaded to the GPU, e.g., as it is in our case where we offload the solver. HALA provides a hala::mixed_engine mode where the inputs sit in CPU memory and are being transferred for a single call, only to be transferred back with the result. The mixed mode could be beneficial in some operations, e.g., large dense <a class="el" href="group__HALABLAS3.html#gae98fae51e118dc3682284a5d001cd946" title="Wrapper to BLAS general matrix multiply xgemm(). ">hala::gemm()</a> where the number of operations far exceeds the data being transferred; however, in a memory bound context of a sparse linear solver where many BLAS 1 and BLAS 2 operations are utilized, the the transfer between each operation can negate any benefits from the GPU acceleration.</dd></dl>
<dl class="section user"><dt></dt><dd>Avoiding repeated data-transfer can be achieved with a single additional overload that encompasses all load/unload operations.</dd></dl>
<div class="fragment"><div class="line"><span class="preprocessor">#ifdef HALA_ENABLE_GPU</span></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeP,  <span class="keyword">class</span> VectorLikeI, <span class="keyword">class</span> VectorLikeV, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeB&gt;</div><div class="line"><span class="keywordtype">int</span> <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(hala::mixed_engine <span class="keyword">const</span> &amp;engine,</div><div class="line">              <span class="keywordtype">int</span> max_iter, <a class="code" href="group__HALACUSTOM.html#ga78609b70f45312e08e520b6ed736ff40">hala::get_precision_type&lt;VectorLikeV&gt;</a> stop_tolerance,</div><div class="line">              VectorLikeP <span class="keyword">const</span> &amp;pntr, VectorLikeI <span class="keyword">const</span> &amp;indx, VectorLikeV <span class="keyword">const</span> &amp;vals,</div><div class="line">              VectorLikeB <span class="keyword">const</span> &amp;b, VectorLikeX &amp;x){</div><div class="line">    <span class="keyword">auto</span> gpu_pntr = engine.gpu().load(pntr);</div><div class="line">    <span class="keyword">auto</span> gpu_indx = engine.gpu().load(indx);</div><div class="line">    <span class="keyword">auto</span> gpu_vals = engine.gpu().load(vals);</div><div class="line">    <span class="keyword">auto</span> gpu_b = engine.gpu().load(b);</div><div class="line">    <span class="keyword">auto</span> gpu_x = <a class="code" href="group__HALAGPUENGINE.html#ga576531f108e7a5ca7f8af1b26c066a69">hala::gpu_bind_vector</a>(engine.gpu(), x);</div><div class="line">    <span class="keywordflow">return</span> <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(engine.gpu(), max_iter, stop_tolerance,</div><div class="line">                     gpu_pntr, gpu_indx, gpu_vals, gpu_b, gpu_x);</div><div class="line">}</div><div class="line"><span class="preprocessor">#endif</span></div></div><!-- fragment --> <dl class="section user"><dt></dt><dd>The mixed overload will be favored over the use of the tempated overload due to the explicit use of hala::mixed_engine. The standard load commands are used and the <a class="el" href="group__HALAGPUENGINE.html#ga576531f108e7a5ca7f8af1b26c066a69" title="Creates an instance of hala::binded_gpu_vector using the device id of the engine. ...">hala::gpu_bind_vector()</a> method is used to bind a CPU and GPU vectors together, so that when the GPU container is destroyed the data will be written back to the CPU one. This enables RAII style of resource management and prevents us from accidentally forgetting to call unload. In addition, the main method call to the overload can be called just like the original CPU-only implementation whith only the engine as an extra variable.</dd></dl>
<div class="fragment"><div class="line"><span class="preprocessor">    #ifdef HALA_ENABLE_GPU</span></div><div class="line">    hala::mixed_engine engine(egpu);</div><div class="line"><span class="preprocessor">    #else</span></div><div class="line">    <a class="code" href="structhala_1_1cpu__engine.html">hala::cpu_engine</a> engine;</div><div class="line"><span class="preprocessor">    #endif</span></div><div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> n : std::vector&lt;int&gt;{4, 8, 16, 32, 64, 128}){</div><div class="line"></div><div class="line">        std::valarray&lt;int&gt; pntr, indx;</div><div class="line">        std::valarray&lt;double&gt; vals, f;</div><div class="line"></div><div class="line">        <a class="code" href="group__HALAEXAMPLE2.html#ga09994cea00d3618d3534c35ddc63757b">discretize_pde</a>(n, pntr, indx, vals, f);</div><div class="line"></div><div class="line">        std::valarray&lt;double&gt; u(0.0, f.size());</div><div class="line"></div><div class="line">        meter.<a class="code" href="structhala_1_1chronometer.html#a4d8fa412a520e583eb0ecbb492d9fb3a">set_start</a>();</div><div class="line">        <span class="keywordtype">int</span> iter = <a class="code" href="example__gpu_8cpp.html#aca7e2def6a5a2447afd9444b80da8459">solve_pcg</a>(engine, max_iter, tolerance, pntr, indx, vals, f, u);</div><div class="line">        <span class="keywordtype">long</span> <span class="keywordtype">long</span> duration = meter.<a class="code" href="structhala_1_1chronometer.html#a411ba500e2322086f19c0501c781ddc5">get_end</a>();</div><div class="line">        assert( iter &lt; max_iter);</div><div class="line"></div><div class="line">        cout &lt;&lt; setw(5) &lt;&lt; iter &lt;&lt; setw(10) &lt;&lt; duration</div><div class="line">             &lt;&lt; setw(10) &lt;&lt; u.size() &lt;&lt; setw(15) &lt;&lt; <a class="code" href="group__HALAEXAMPLE2.html#gad3706f9a2a499c7e64b7b7ee3ab81f50">compute_l2_error</a>(u) &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div><div class="line">    }</div></div><!-- fragment --><p> The neede for pre-processor guard directives is also reduced to the definition of the two engines.</p>
<dl class="section user"><dt>Engine vs. Engined-Vector</dt><dd>The <a class="el" href="group__HALAWAXENGINED.html#gaf4ae7eba405e49b271e1279c2ec3f170" title="Creates a bind between the engine and the vector. ">hala::bind_engine_vector()</a> approach used in the example offers several advantages:<ul>
<li>the original CPU-only code does not need to be changed or updated, which is favorable when working with complex and already tested algorithms</li>
<li>there is no need to carry the redundant engine variable to each call</li>
</ul>
</dd></dl>
<dl class="section user"><dt></dt><dd>On the other hand, the engine offers other advantages:<ul>
<li>the engine calls are more explicit which is advantageous in cases when CPU and GPU bound methods are mixed in a single algorithm, e.g., GMRES where the matrix-vector product is computed on the GPU while the orthogonalization coefficients are handled on the CPU</li>
<li>the template overload resolution is simpler and less prone to compiler quirks</li>
</ul>
</dd></dl>
<p><a class="anchor" id="Example2Solvers"></a></p><dl class="section user"><dt>Native HALA Solvers</dt><dd>HALA includes several sparse iterative solvers, including the preconditioned conjugate-gradient with the options for a ILU and a user provided preconditioner. See the <a class="el" href="group__HALASOLVERS.html">HALA Solver Algorithms</a> solvers documentation. </dd></dl>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga09994cea00d3618d3534c35ddc63757b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga09994cea00d3618d3534c35ddc63757b">&#9670;&nbsp;</a></span>discretize_pde()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename scalar_type &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void discretize_pde </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_side</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::valarray&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>pntr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::valarray&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>indx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::valarray&lt; scalar_type &gt; &amp;&#160;</td>
          <td class="paramname"><em>vals</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::valarray&lt; scalar_type &gt; &amp;&#160;</td>
          <td class="paramname"><em>f</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the discretization of the PDE and the right hand side. </p>
<ul>
<li><b>num_side</b> is the number of points to use on each side square grid, the size of the linear system is num_side squared by num_side squared</li>
<li><b>pntr</b>, <b>indx</b>, <b>vals</b> describe the sparse matrix that approximates the left-hand-side operator</li>
<li><b>f</b> is the discretization of the right-hand-side forcing term </li>
</ul>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.15-->
<!-- start footer part -->
<!-- <div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
<!--  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div> -->
</body>
</html>
