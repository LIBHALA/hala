<!-- HTML header for doxygen 1.8.15-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>HALA: Handy Accelerated Linear Algebra v1.0: wax/hala_blas_extensions.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="hala.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
    <div class="doxygen">
            <a href="http://www.doxygen.org/index.html">
                <img class="footer" src="doxygen.png" alt="doxygen"/>
                </a> 1.8.13
    </div>
   <div id="projectname">HALA: Handy Accelerated Linear Algebra v1.0
   <!--         <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
 -->
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('hala__blas__extensions_8hpp_source.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">hala_blas_extensions.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef __HALA_BLAS_EXTENSIONS_HPP</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define __HALA_BLAS_EXTENSIONS_HPP</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> * Code Author: Miroslav Stoyanov</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * Copyright (C) 2018  Miroslav Stoyanov</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> * This file is part of</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> * Hardware Accelerated Linear Algebra (HALA)</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &quot;hala_extensions_checker.hpp&quot;</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacehala.html">hala</a>{</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> FPA, <span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY&gt;</div><div class="line"><a name="l00051"></a><span class="lineno"><a class="line" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">   51</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">batch_axpy</a>(<span class="keywordtype">int</span> batch_size, FPA alphac, VectorLikeA <span class="keyword">const</span> &amp;alpha, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY &amp;&amp;y){</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(alpha, x, y);</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;    assert( <a class="code" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">valid::batch_axpy</a>(batch_size, alpha, x, y) );</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    <span class="keywordtype">int</span> N = <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x) / batch_size;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    <span class="keyword">using</span> standard_type = <a class="code" href="group__HALACUSTOM.html#gaeb090a328015649aed8ed8bb9b5e4980">get_standard_type&lt;VectorLikeA&gt;</a>;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    <span class="keyword">auto</span> fpalpha = <a class="code" href="namespacehala.html#a15f4cd15d6f2fee76d37a6543539b6a4">get_cast</a>&lt;standard_type&gt;(alphac);</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;    <span class="keyword">auto</span> salphs = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(alpha);</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;    <span class="keyword">auto</span> sx = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(x);</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;    <span class="keyword">auto</span> sy = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(y);</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0; i&lt;batch_size; i++){</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;        <span class="keyword">auto</span> wrap = <a class="code" href="group__HALACPUENGINE.html#ga1754bbdc7b056afb54044fc35bd4d015">wrap_array</a>(&amp;sy[<a class="code" href="namespacehala.html#a98850706b7be2eb74266c994d1030a37">hala_size</a>(i, N)], N);</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;        <a class="code" href="group__HALABLAS1.html#ga0dff938a94c75c58427ede241c05429b">axpy</a>(N, fpalpha * salphs[i], &amp;sx[<a class="code" href="namespacehala.html#a98850706b7be2eb74266c994d1030a37">hala_size</a>(i, N)], 1, wrap, 1);</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    }</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;}</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="keyword">template</span>&lt;<span class="keywordtype">bool</span> conjugate = true, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeR&gt;</div><div class="line"><a name="l00084"></a><span class="lineno"><a class="line" href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">   84</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">batch_dot</a>(<span class="keywordtype">int</span> batch_size, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeR &amp;&amp;result){</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(x, y, result);</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    assert( <a class="code" href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">valid::batch_dot</a>(batch_size, x, y) );</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;    <span class="keywordtype">int</span> N = <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x) / batch_size;</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;    <a class="code" href="namespacehala.html#a22a221a072d52df2fc701b26836835bd">check_set_size</a>(<a class="code" href="namespacehala.html#adef045f05b6ffe8417261fe6b4a4eec9">assume_output</a>, result, batch_size);</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    <span class="keyword">auto</span> sx = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(x);</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    <span class="keyword">auto</span> sy = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(y);</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    <span class="keyword">auto</span> sresult = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(result);</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0; i&lt;batch_size; i++)</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;        sresult[i] = dot&lt;conjugate&gt;(N, &amp;sx[<a class="code" href="namespacehala.html#a98850706b7be2eb74266c994d1030a37">hala_size</a>(i, N)], 1, &amp;sy[<a class="code" href="namespacehala.html#a98850706b7be2eb74266c994d1030a37">hala_size</a>(i, N)], 1);</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;}</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeX&gt;</div><div class="line"><a name="l00114"></a><span class="lineno"><a class="line" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">  114</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">batch_scal</a>(<span class="keywordtype">int</span> batch_size, VectorLikeA <span class="keyword">const</span> &amp;alpha, VectorLikeX &amp;&amp;x){</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(alpha, x);</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    assert( <a class="code" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">valid::batch_scal</a>(batch_size, alpha, x) );</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    <span class="keywordtype">int</span> N = <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x) / batch_size;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    <span class="keyword">auto</span> sx = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(x);</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;    <span class="keyword">auto</span> sa = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(alpha);</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0; i&lt;batch_size; i++)</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;        <a class="code" href="group__HALABLAS1.html#ga3d8f14a164c86b89abbb4e7bfbdca660">scal</a>(N, sa[i], &amp;sx[<a class="code" href="namespacehala.html#a98850706b7be2eb74266c994d1030a37">hala_size</a>(i, N)], 1);</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;}</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeZ&gt;</div><div class="line"><a name="l00139"></a><span class="lineno"><a class="line" href="group__HALAWAXBLAS.html#ga27d50beba7026da717f6ebc52ac5ca6a">  139</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga27d50beba7026da717f6ebc52ac5ca6a">vdivide</a>(VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeZ &amp;&amp;z){</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(x, y, z);</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;    assert( <a class="code" href="group__HALACUSTOM.html#gacb23ab0a92ecead8007cf9aa8dc972db">get_size</a>(x) == <a class="code" href="group__HALACUSTOM.html#gacb23ab0a92ecead8007cf9aa8dc972db">get_size</a>(y) );</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;    <span class="keywordtype">size_t</span> N = <a class="code" href="group__HALACUSTOM.html#gacb23ab0a92ecead8007cf9aa8dc972db">get_size</a>(x);</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;    <a class="code" href="namespacehala.html#a22a221a072d52df2fc701b26836835bd">check_set_size</a>(<a class="code" href="namespacehala.html#adef045f05b6ffe8417261fe6b4a4eec9">assume_output</a>, z, N);</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;    <span class="keyword">auto</span> sx = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(x);</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    <span class="keyword">auto</span> sy = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(y);</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    <span class="keyword">auto</span> sz = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(z);</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i=0; i&lt;N; i++)</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;        sz[i] = sx[i] / sy[i];</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;}</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;<span class="preprocessor">#ifndef __HALA_DOXYGEN_SKIP // tell Doxygen to skip this section (overloads are documented with the main methods)</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> FPA, <span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY&gt;</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">batch_axpy</a>(<a class="code" href="structhala_1_1cpu__engine.html">cpu_engine</a> <span class="keyword">const</span>&amp;, <span class="keywordtype">int</span> batch_size, FPA alphac, VectorLikeA <span class="keyword">const</span> &amp;alpha, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY &amp;&amp;y){</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    <a class="code" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">batch_axpy</a>(batch_size, alphac, alpha, x, y);</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;}</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="keyword">template</span>&lt;<span class="keywordtype">bool</span> conjugate = true, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeR&gt;</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">batch_dot</a>(<a class="code" href="structhala_1_1cpu__engine.html">cpu_engine</a> <span class="keyword">const</span>&amp;, <span class="keywordtype">int</span> batch_size, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeR &amp;&amp;result){</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;    batch_dot&lt;conjugate&gt;(batch_size, x, y, result);</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;}</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeR&gt;</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="keywordtype">void</span> batch_dotu(<span class="keywordtype">int</span> batch_size, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeR &amp;&amp;result){</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;    batch_dot&lt;false&gt;(batch_size, x, y, std::forward&lt;VectorLikeR&gt;(result));</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;}</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeR&gt;</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="keywordtype">void</span> batch_dotu(<a class="code" href="structhala_1_1cpu__engine.html">cpu_engine</a> <span class="keyword">const</span>&amp;, <span class="keywordtype">int</span> batch_size, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeR &amp;&amp;result){</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;    batch_dot&lt;false&gt;(batch_size, x, y, std::forward&lt;VectorLikeR&gt;(result));</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;}</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeX&gt;</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">batch_scal</a>(<a class="code" href="structhala_1_1cpu__engine.html">cpu_engine</a> <span class="keyword">const</span>&amp;, <span class="keywordtype">int</span> batch_size, VectorLikeA <span class="keyword">const</span> &amp;alpha, VectorLikeX &amp;&amp;x){</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;    <a class="code" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">batch_scal</a>(batch_size, alpha, x);</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;}</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeZ&gt;</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga27d50beba7026da717f6ebc52ac5ca6a">vdivide</a>(<a class="code" href="structhala_1_1cpu__engine.html">cpu_engine</a> <span class="keyword">const</span>&amp;, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeZ &amp;&amp;z){</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;    <a class="code" href="group__HALAWAXBLAS.html#ga27d50beba7026da717f6ebc52ac5ca6a">vdivide</a>(x, y, z);</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;}</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="preprocessor">#ifdef HALA_ENABLE_GPU</span></div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeAt&gt;</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;<span class="keywordtype">void</span> transpose(<a class="code" href="structhala_1_1gpu__engine.html">gpu_engine</a> <span class="keyword">const</span> &amp;engine, <span class="keywordtype">int</span> M, <span class="keywordtype">int</span> N, VectorLikeA <span class="keyword">const</span> &amp;A, <span class="keywordtype">int</span> lda, VectorLikeAt &amp;At, <span class="keywordtype">int</span> ldat){</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;    <a class="code" href="structhala_1_1gpu__pntr.html">gpu_pntr&lt;host_pntr&gt;</a> hold(engine);</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;    <a class="code" href="group__HALAGPUBLAS0.html#gaf1ae82cd4ea22a5eb0aec270718545be">geam</a>(engine, <span class="charliteral">&#39;T&#39;</span>, <span class="charliteral">&#39;T&#39;</span>, N, M, 1, A, lda, 0, A, lda, At, ldat);</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;}</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;<span class="preprocessor">#ifndef __HALA_DOXYGEN_SKIP // tell Doxygen to skip this section (overloads are documented with the main methods)</span></div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> FPA, <span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY&gt;</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">batch_axpy</a>(<a class="code" href="structhala_1_1gpu__engine.html">gpu_engine</a> <span class="keyword">const</span> &amp;engine, <span class="keywordtype">int</span> batch_size, FPA alphac, VectorLikeA <span class="keyword">const</span> &amp;alpha, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY &amp;&amp;y){</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(alpha, x, y);</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;    engine.<a class="code" href="structhala_1_1gpu__engine.html#a09de76a77b7250e7884b298f5b35791f">check_gpu</a>(x, y, alpha);</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;    assert( <a class="code" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">valid::batch_axpy</a>(batch_size, alpha, x, y) );</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;    <span class="keywordtype">int</span> N = <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x) / batch_size;</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;    <span class="keyword">using</span> scalar_type = <a class="code" href="group__HALACUSTOM.html#gab93c1d2ec9a0e8222f141d16c56a1b58">get_scalar_type&lt;VectorLikeA&gt;</a>;</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;    <span class="keyword">auto</span> fpalpha = <a class="code" href="namespacehala.html#a15f4cd15d6f2fee76d37a6543539b6a4">get_cast</a>&lt;scalar_type&gt;(alphac);</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;    <span class="keyword">auto</span> scaledx = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">new_vector</a>(engine, x);</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;    <a class="code" href="group__HALAGPUBLAS0.html#ga913ed4bb219b279b396fe0a9ad5986bd">dgmm</a>(engine, <span class="charliteral">&#39;R&#39;</span>, N, batch_size, x, alpha, scaledx);</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;    <a class="code" href="group__HALABLAS1.html#ga0dff938a94c75c58427ede241c05429b">axpy</a>(engine, fpalpha, scaledx, y);</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;}</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;<span class="keyword">template</span>&lt;<span class="keywordtype">bool</span> conjugate = true, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeR&gt;</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">batch_dot</a>(<a class="code" href="structhala_1_1gpu__engine.html">gpu_engine</a> <span class="keyword">const</span> &amp;engine, <span class="keywordtype">int</span> batch_size, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeR &amp;&amp;result){</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(x, y, result);</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;    engine.<a class="code" href="structhala_1_1gpu__engine.html#a09de76a77b7250e7884b298f5b35791f">check_gpu</a>(x, y, result);</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;    assert( <a class="code" href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">valid::batch_dot</a>(batch_size, x, y) );</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;    <span class="keywordtype">int</span> N = <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x) / batch_size;</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;    <a class="code" href="namespacehala.html#a22a221a072d52df2fc701b26836835bd">check_set_size</a>(<a class="code" href="namespacehala.html#adef045f05b6ffe8417261fe6b4a4eec9">assume_output</a>, result, batch_size);</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;    <a class="code" href="structhala_1_1gpu__pntr.html">gpu_pntr&lt;host_pntr&gt;</a> hold(engine);</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;    <span class="keyword">using</span> scalar_type = <a class="code" href="group__HALACUSTOM.html#gab93c1d2ec9a0e8222f141d16c56a1b58">get_scalar_type&lt;VectorLikeX&gt;</a>;</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;    <span class="keyword">auto</span> product = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">new_vector</a>(engine, x); <span class="comment">// engine.vector&lt;scalar_type&gt;(get_size(x));</span></div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;    <span class="keywordflow">if</span> __HALA_CONSTEXPR_IF__ (conjugate &amp;&amp; <a class="code" href="structhala_1_1is__complex.html">is_complex&lt;scalar_type&gt;::value</a>){</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;        <span class="comment">// need to manually conjugate x</span></div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;        <span class="keyword">auto</span> x_conj = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">new_vector</a>(engine, x);</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;        <a class="code" href="group__HALAGPUBLAS0.html#gaf1ae82cd4ea22a5eb0aec270718545be">geam</a>(engine, <span class="charliteral">&#39;C&#39;</span>, <span class="charliteral">&#39;C&#39;</span>, <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x), 1, 1.0, x, 1, 0, x, 1, x_conj, <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x));</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;        <a class="code" href="group__HALAGPUBLAS0.html#ga913ed4bb219b279b396fe0a9ad5986bd">dgmm</a>(engine, <span class="charliteral">&#39;L&#39;</span>, <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x), 1, x_conj, y, product);</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;    }<span class="keywordflow">else</span>{</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;        <a class="code" href="group__HALAGPUBLAS0.html#ga913ed4bb219b279b396fe0a9ad5986bd">dgmm</a>(engine, <span class="charliteral">&#39;L&#39;</span>, <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x), 1, x, y, product);</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;    }</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;    <span class="keyword">auto</span> gpu_ones = engine.<a class="code" href="structhala_1_1gpu__engine.html#a144e0aa50a1269f02014f72bb457ff9e">vector</a>&lt;scalar_type&gt;(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(N), get_cast&lt;scalar_type&gt;(1.0));</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;    <a class="code" href="group__HALABLAS2.html#ga925bf0c14261ed419bb931e85658f6eb">gemv</a>(engine, <span class="charliteral">&#39;T&#39;</span>, N, batch_size, 1.0, product, gpu_ones, 0.0, result);</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;}</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeR&gt;</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;<span class="keywordtype">void</span> batch_dotu(<a class="code" href="structhala_1_1gpu__engine.html">gpu_engine</a> <span class="keyword">const</span> &amp;engine, <span class="keywordtype">int</span> batch_size, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeR &amp;&amp;result){</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;    batch_dot&lt;false&gt;(engine, batch_size, x, y, std::forward&lt;VectorLikeR&gt;(result));</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;}</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeX&gt;</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">batch_scal</a>(<a class="code" href="structhala_1_1gpu__engine.html">gpu_engine</a> <span class="keyword">const</span> &amp;engine, <span class="keywordtype">int</span> batch_size, VectorLikeA <span class="keyword">const</span> &amp;alpha, VectorLikeX &amp;&amp;x){</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(alpha, x);</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;    engine.<a class="code" href="structhala_1_1gpu__engine.html#a09de76a77b7250e7884b298f5b35791f">check_gpu</a>(alpha, x);</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;    assert( <a class="code" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">valid::batch_scal</a>(batch_size, alpha, x) );</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;    <span class="keywordtype">int</span> N = <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x) / batch_size;</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;    <span class="keyword">auto</span> tmp = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">new_vector</a>(engine, x);</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;    <a class="code" href="group__HALAGPUBLAS0.html#ga913ed4bb219b279b396fe0a9ad5986bd">dgmm</a>(engine, <span class="charliteral">&#39;R&#39;</span>, N, batch_size, x, N, alpha, 1, tmp, N);</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;    <a class="code" href="group__HALABLAS1.html#ga199fd708ca4ff8b2c65b6ee47491b37d">vcopy</a>(engine, tmp, x);</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;}</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeZ&gt;</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga27d50beba7026da717f6ebc52ac5ca6a">vdivide</a>(<a class="code" href="structhala_1_1gpu__engine.html">gpu_engine</a> <span class="keyword">const</span> &amp;engine, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeZ &amp;&amp;z){</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(x, y, z);</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;    engine.<a class="code" href="structhala_1_1gpu__engine.html#a09de76a77b7250e7884b298f5b35791f">check_gpu</a>(x, y, z);</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;    assert( <a class="code" href="group__HALACUSTOM.html#gacb23ab0a92ecead8007cf9aa8dc972db">get_size</a>(x) == <a class="code" href="group__HALACUSTOM.html#gacb23ab0a92ecead8007cf9aa8dc972db">get_size</a>(y) );</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;    <span class="keywordtype">int</span> N = <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x);</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;    <a class="code" href="group__HALABLAS1.html#ga199fd708ca4ff8b2c65b6ee47491b37d">hala::vcopy</a>(engine, x, z);</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;    <a class="code" href="group__HALABLAS2.html#ga9ff50eeb8bb1682349d7a68d2fdfe610">hala::tbsv</a>(engine, <span class="charliteral">&#39;U&#39;</span>, <span class="charliteral">&#39;N&#39;</span>, <span class="charliteral">&#39;N&#39;</span>, N, 0, y, z);</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;}</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeAt&gt;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;<span class="keywordtype">void</span> transpose(<a class="code" href="structhala_1_1gpu__engine.html">gpu_engine</a> <span class="keyword">const</span> &amp;engine, <span class="keywordtype">int</span> M, <span class="keywordtype">int</span> N, VectorLikeA <span class="keyword">const</span> &amp;A, VectorLikeAt &amp;At, <span class="keywordtype">int</span> lda = -1, <span class="keywordtype">int</span> ldat = -1){</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;    <a class="code" href="namespacehala_1_1valid.html#ad23b9f8bdc1526aa44118fd70e427c27">valid::default_ld</a>(M, lda);</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;    <a class="code" href="namespacehala_1_1valid.html#ad23b9f8bdc1526aa44118fd70e427c27">valid::default_ld</a>(N, ldat);</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;    transpose(engine, M, N, A, lda, At, ldat);</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;}</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeAt&gt;</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;<span class="keywordtype">void</span> transpose(mixed_engine <span class="keyword">const</span> &amp;e, <span class="keywordtype">int</span> M, <span class="keywordtype">int</span> N, VectorLikeA <span class="keyword">const</span> &amp;A, <span class="keywordtype">int</span> lda, VectorLikeAt &amp;At, <span class="keywordtype">int</span> ldat){</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;    <span class="keyword">auto</span> gA = e.gpu().load(A);</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;    <span class="keyword">auto</span> gAt = <a class="code" href="group__HALAGPUENGINE.html#ga576531f108e7a5ca7f8af1b26c066a69">gpu_bind_vector</a>(e.gpu(), At);</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;    transpose(e.gpu(), M, N, gA, gAt, lda, ldat);</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;}</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeAt&gt;</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;<span class="keywordtype">void</span> transpose(mixed_engine <span class="keyword">const</span> &amp;e, <span class="keywordtype">int</span> M, <span class="keywordtype">int</span> N, VectorLikeA <span class="keyword">const</span> &amp;A, VectorLikeAt &amp;At, <span class="keywordtype">int</span> lda = -1, <span class="keywordtype">int</span> ldat = -1){</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;    transpose(e, M, N, A, At, lda, ldat);</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;}</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> FPA, <span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY&gt;</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">batch_axpy</a>(mixed_engine <span class="keyword">const</span> &amp;e, <span class="keywordtype">int</span> batch_size, FPA alphac, VectorLikeA <span class="keyword">const</span> &amp;alpha, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY &amp;y){</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;    <a class="code" href="structhala_1_1gpu__pntr.html">gpu_pntr&lt;host_pntr&gt;</a> hold(e.gpu());</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;    <span class="keyword">auto</span> galpha = e.gpu().load(alpha);</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;    <span class="keyword">auto</span> gx = e.gpu().load(x);</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;    <span class="keyword">auto</span> gy = <a class="code" href="group__HALAGPUENGINE.html#ga576531f108e7a5ca7f8af1b26c066a69">gpu_bind_vector</a>(e.gpu(), y);</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;    <a class="code" href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">batch_axpy</a>(e.gpu(), batch_size, alphac, galpha, gx, gy);</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;}</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;<span class="keyword">template</span>&lt;<span class="keywordtype">bool</span> conjugate = true, <span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeR&gt;</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">batch_dot</a>(mixed_engine <span class="keyword">const</span> &amp;e, <span class="keywordtype">int</span> batch_size, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeR &amp;result){</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;    <span class="keyword">auto</span> gx = e.gpu().load(x);</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;    <span class="keyword">auto</span> gy = e.gpu().load(y);</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;    <span class="keyword">auto</span> gresult = <a class="code" href="group__HALAGPUENGINE.html#ga576531f108e7a5ca7f8af1b26c066a69">gpu_bind_vector</a>(e.gpu(), result);</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    batch_dot&lt;conjugate&gt;(e.gpu(), batch_size, gx, gy, gresult);</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;}</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeR&gt;</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="keywordtype">void</span> batch_dotu(mixed_engine <span class="keyword">const</span> &amp;e, <span class="keywordtype">int</span> batch_size, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeR &amp;result){</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;    batch_dot&lt;false&gt;(e, batch_size, x, y, result);</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;}</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeA, <span class="keyword">class</span> VectorLikeX&gt;</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">batch_scal</a>(mixed_engine <span class="keyword">const</span> &amp;e, <span class="keywordtype">int</span> batch_size, VectorLikeA <span class="keyword">const</span> &amp;alpha, VectorLikeX &amp;&amp;x){</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;    <span class="keyword">auto</span> ga = e.gpu().load(alpha);</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;    <span class="keyword">auto</span> gx = <a class="code" href="group__HALAGPUENGINE.html#ga576531f108e7a5ca7f8af1b26c066a69">gpu_bind_vector</a>(e.gpu(), x);</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;    <a class="code" href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">batch_scal</a>(e.gpu(), batch_size, ga, gx);</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;}</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLikeX, <span class="keyword">class</span> VectorLikeY, <span class="keyword">class</span> VectorLikeZ&gt;</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;<span class="keywordtype">void</span> <a class="code" href="group__HALAWAXBLAS.html#ga27d50beba7026da717f6ebc52ac5ca6a">vdivide</a>(mixed_engine <span class="keyword">const</span> &amp;e, VectorLikeX <span class="keyword">const</span> &amp;x, VectorLikeY <span class="keyword">const</span> &amp;y, VectorLikeZ &amp;&amp;z){</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;    <span class="keyword">auto</span> gx = e.gpu().load(x);</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;    <span class="keyword">auto</span> gy = e.gpu().load(y);</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;    <span class="keyword">auto</span> gz = <a class="code" href="group__HALAGPUENGINE.html#ga576531f108e7a5ca7f8af1b26c066a69">gpu_bind_vector</a>(e.gpu(), z);</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;    <a class="code" href="group__HALAWAXBLAS.html#ga27d50beba7026da717f6ebc52ac5ca6a">vdivide</a>(e.gpu(), gx, gy, gz);</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;}</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="preprocessor">#endif // end overloads</span></div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;<span class="preprocessor">#endif // end of CUDA</span></div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> cengine, <span class="keyword">class</span> VectorLike&gt;</div><div class="line"><a name="l00354"></a><span class="lineno"><a class="line" href="group__HALAWAXBLAS.html#ga329f68a7f474c1502564d9afe5c6c729">  354</a></span>&#160;<span class="keyword">auto</span> <a class="code" href="group__HALAWAXBLAS.html#ga329f68a7f474c1502564d9afe5c6c729">batch_max_norm2</a>(cengine <span class="keyword">const</span> &amp;engine, <span class="keywordtype">int</span> batch_size, VectorLike <span class="keyword">const</span> &amp;x){</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;    <a class="code" href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">check_types</a>(x);</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;    assert( batch_size &gt; 0 );</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;    assert( <a class="code" href="namespacehala.html#ac5f569cff6185ec959911b50370e6af9">check_size</a>(x, batch_size, <a class="code" href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">get_size_int</a>(x) / batch_size) );</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;    <span class="keyword">auto</span> norms = <a class="code" href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">new_vector</a>(engine, x);</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;    <a class="code" href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">batch_dot</a>(engine, batch_size, x, x, norms);</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;    <span class="keywordtype">int</span> nmax = <a class="code" href="group__HALABLAS1.html#ga4f2f0c0b1c17c7a8ee5fe664fe0d652c">iamax</a>(engine, norms);</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;    <span class="keyword">auto</span> nd = <a class="code" href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">get_standard_data</a>(norms);</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;    <span class="keywordflow">return</span> std::sqrt( <a class="code" href="group__HALABLAS1.html#ga48f8d9b686ef4a9cdb69897e3f22bbe5">norm2</a>(engine, 1, &amp;nd[nmax], 1) );</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;}</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;<span class="preprocessor">#ifndef __HALA_DOXYGEN_SKIP // tell Doxygen to skip this section (overloads are documented with the main methods)</span></div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLike&gt;</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;<span class="keyword">auto</span> <a class="code" href="group__HALAWAXBLAS.html#ga329f68a7f474c1502564d9afe5c6c729">batch_max_norm2</a>(<span class="keywordtype">int</span> batch_size, VectorLike <span class="keyword">const</span> &amp;x){</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;    <a class="code" href="structhala_1_1cpu__engine.html">cpu_engine</a> <span class="keyword">const</span> ecpu;</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="group__HALAWAXBLAS.html#ga329f68a7f474c1502564d9afe5c6c729">batch_max_norm2</a>(ecpu, batch_size, x);</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;}</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;<span class="preprocessor">#ifdef HALA_ENABLE_GPU</span></div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> VectorLike&gt;</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;<span class="keyword">auto</span> <a class="code" href="group__HALAWAXBLAS.html#ga329f68a7f474c1502564d9afe5c6c729">batch_max_norm2</a>(mixed_engine <span class="keyword">const</span> &amp;e, <span class="keywordtype">int</span> batch_size, VectorLike <span class="keyword">const</span> &amp;x){</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;    <span class="keyword">auto</span> gx = e.gpu().load(x);</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="group__HALAWAXBLAS.html#ga329f68a7f474c1502564d9afe5c6c729">batch_max_norm2</a>(e.gpu(), batch_size, gx);</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;}</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;}</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;<span class="preprocessor">#endif</span></div><div class="ttc" id="structhala_1_1is__complex_html"><div class="ttname"><a href="structhala_1_1is__complex.html">hala::is_complex</a></div><div class="ttdoc">Defines value = true if the type T is std::complex&lt;float&gt; or std::complex&lt;double&gt;. </div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:286</div></div>
<div class="ttc" id="namespacehala_html_a9e761656c953c9fa8646a208c7321eda"><div class="ttname"><a href="namespacehala.html#a9e761656c953c9fa8646a208c7321eda">hala::get_size_int</a></div><div class="ttdeci">int get_size_int(VectorLike const &amp;x)</div><div class="ttdoc">Take the output of get_size() and type-cast it to int. </div><div class="ttdef"><b>Definition:</b> hala_vector_defines.hpp:358</div></div>
<div class="ttc" id="namespacehala_html_a22a221a072d52df2fc701b26836835bd"><div class="ttname"><a href="namespacehala.html#a22a221a072d52df2fc701b26836835bd">hala::check_set_size</a></div><div class="ttdeci">void check_set_size(bool strict_output, VectorLike &amp;x, SizeType required_size)</div><div class="ttdoc">If x is strictly used as output and if the size is insufficient, then resize it; otherwise call asser...</div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:140</div></div>
<div class="ttc" id="group__HALACPUENGINE_html_ga830472d103ac598f3ca1c5204a5c0991"><div class="ttname"><a href="group__HALACPUENGINE.html#ga830472d103ac598f3ca1c5204a5c0991">hala::new_vector</a></div><div class="ttdeci">auto new_vector(cpu_engine const &amp;engine, VectorLike const &amp;)</div><div class="ttdoc">Returns a default vector with the default constructor. </div><div class="ttdef"><b>Definition:</b> hala_cpu_engine.hpp:187</div></div>
<div class="ttc" id="namespacehala_html_adef045f05b6ffe8417261fe6b4a4eec9"><div class="ttname"><a href="namespacehala.html#adef045f05b6ffe8417261fe6b4a4eec9">hala::assume_output</a></div><div class="ttdeci">constexpr bool assume_output</div><div class="ttdoc">Marks a variable as output only, allows for expressive calls to check_set_size(). ...</div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:163</div></div>
<div class="ttc" id="group__HALABLAS1_html_ga0dff938a94c75c58427ede241c05429b"><div class="ttname"><a href="group__HALABLAS1.html#ga0dff938a94c75c58427ede241c05429b">hala::axpy</a></div><div class="ttdeci">void axpy(int N, FS alpha, VectorLikeX const &amp;x, int incx, VectorLikeY &amp;&amp;y, int incy)</div><div class="ttdoc">Wrapper to BLAS vector scaled addition xaxpy(). </div><div class="ttdef"><b>Definition:</b> hala_blas_1.hpp:210</div></div>
<div class="ttc" id="group__HALABLAS1_html_ga199fd708ca4ff8b2c65b6ee47491b37d"><div class="ttname"><a href="group__HALABLAS1.html#ga199fd708ca4ff8b2c65b6ee47491b37d">hala::vcopy</a></div><div class="ttdeci">void vcopy(int N, VectorLikeX const &amp;x, int incx, VectorLikeY &amp;&amp;y, int incy)</div><div class="ttdoc">Wrapper to BLAS xcopy() methods. </div><div class="ttdef"><b>Definition:</b> hala_blas_1.hpp:54</div></div>
<div class="ttc" id="group__HALACUSTOM_html_gaeb090a328015649aed8ed8bb9b5e4980"><div class="ttname"><a href="group__HALACUSTOM.html#gaeb090a328015649aed8ed8bb9b5e4980">hala::get_standard_type</a></div><div class="ttdeci">typename define_standard_type&lt; typename define_type&lt; VectorLike &gt;::value_type &gt;::value_type get_standard_type</div><div class="ttdoc">Alias to the standard equivalent for the scalar type of a vector-like class. </div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:74</div></div>
<div class="ttc" id="namespacehala_html_a2473b505275b0ddcb9bf0b22382bacf8"><div class="ttname"><a href="namespacehala.html#a2473b505275b0ddcb9bf0b22382bacf8">hala::check_types</a></div><div class="ttdeci">void check_types(VectorLike const &amp;)</div><div class="ttdoc">Static asserts that the value_type of VectorLike is one of float, double, complex&lt;float&gt;, complex&lt;double&gt;. </div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:197</div></div>
<div class="ttc" id="namespacehala_html_a81bb288a038255685ad7c8273cee53e0"><div class="ttname"><a href="namespacehala.html#a81bb288a038255685ad7c8273cee53e0">hala::get_standard_data</a></div><div class="ttdeci">auto get_standard_data(VectorLike &amp;x)</div><div class="ttdoc">Using reinterpret_cast, get a raw-array of type matching the base. </div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:92</div></div>
<div class="ttc" id="group__HALAWAXBLAS_html_ga76ea43e79bfb03934cc07d297f6726b2"><div class="ttname"><a href="group__HALAWAXBLAS.html#ga76ea43e79bfb03934cc07d297f6726b2">hala::batch_dot</a></div><div class="ttdeci">void batch_dot(int batch_size, VectorLikeX const &amp;x, VectorLikeY const &amp;y, VectorLikeR &amp;&amp;result)</div><div class="ttdoc">Computes the dot-product for a batch of one dimensional vectors. </div><div class="ttdef"><b>Definition:</b> hala_blas_extensions.hpp:84</div></div>
<div class="ttc" id="group__HALAGPUBLAS0_html_gaf1ae82cd4ea22a5eb0aec270718545be"><div class="ttname"><a href="group__HALAGPUBLAS0.html#gaf1ae82cd4ea22a5eb0aec270718545be">hala::geam</a></div><div class="ttdeci">void geam(gpu_engine const &amp;engine, char transa, char transb, int M, int N, FPa alpha, VectorLikeA const &amp;A, int lda, FPb beta, VectorLikeB const &amp;B, int ldb, VectorLikeC &amp;&amp;C, int ldc)</div><div class="ttdoc">Wrapper to GPU-BLAS matrix addition Xgeam(). </div><div class="ttdef"><b>Definition:</b> hala_gpu_blas0.hpp:57</div></div>
<div class="ttc" id="structhala_1_1cpu__engine_html"><div class="ttname"><a href="structhala_1_1cpu__engine.html">hala::cpu_engine</a></div><div class="ttdoc">The CPU Engine. </div><div class="ttdef"><b>Definition:</b> hala_cpu_engine.hpp:111</div></div>
<div class="ttc" id="group__HALAWAXBLAS_html_ga19a9aa4205df25be0bade0c586488640"><div class="ttname"><a href="group__HALAWAXBLAS.html#ga19a9aa4205df25be0bade0c586488640">hala::batch_axpy</a></div><div class="ttdeci">void batch_axpy(int batch_size, FPA alphac, VectorLikeA const &amp;alpha, VectorLikeX const &amp;x, VectorLikeY &amp;&amp;y)</div><div class="ttdoc">Compute the scaled vector sum of a batch of one dimensional vectors and scalars, where the vectors ar...</div><div class="ttdef"><b>Definition:</b> hala_blas_extensions.hpp:51</div></div>
<div class="ttc" id="group__HALACPUENGINE_html_ga1754bbdc7b056afb54044fc35bd4d015"><div class="ttname"><a href="group__HALACPUENGINE.html#ga1754bbdc7b056afb54044fc35bd4d015">hala::wrap_array</a></div><div class="ttdeci">auto wrap_array(cpu_engine const &amp;, ArrayType arr[], size_t num_entries)</div><div class="ttdoc">Create an array wrapper for the corresponding engine. </div><div class="ttdef"><b>Definition:</b> hala_cpu_engine.hpp:233</div></div>
<div class="ttc" id="group__HALABLAS1_html_ga3d8f14a164c86b89abbb4e7bfbdca660"><div class="ttname"><a href="group__HALABLAS1.html#ga3d8f14a164c86b89abbb4e7bfbdca660">hala::scal</a></div><div class="ttdeci">void scal(int N, FS alpha, VectorLikeX &amp;&amp;x, int incx)</div><div class="ttdoc">Wrapper to BLAS vector scale by constant xscal(). </div><div class="ttdef"><b>Definition:</b> hala_blas_1.hpp:317</div></div>
<div class="ttc" id="group__HALAGPUENGINE_html_ga576531f108e7a5ca7f8af1b26c066a69"><div class="ttname"><a href="group__HALAGPUENGINE.html#ga576531f108e7a5ca7f8af1b26c066a69">hala::gpu_bind_vector</a></div><div class="ttdeci">auto gpu_bind_vector(gpu_engine const &amp;e, VectorLike &amp;x)</div><div class="ttdoc">Creates an instance of hala::binded_gpu_vector using the device id of the engine. ...</div><div class="ttdef"><b>Definition:</b> hala_gpu_engine.hpp:419</div></div>
<div class="ttc" id="structhala_1_1gpu__engine_html_a144e0aa50a1269f02014f72bb457ff9e"><div class="ttname"><a href="structhala_1_1gpu__engine.html#a144e0aa50a1269f02014f72bb457ff9e">hala::gpu_engine::vector</a></div><div class="ttdeci">auto vector(size_t num_entries, T value) const</div><div class="ttdoc">Return a hala::gpu_vector associated with the current device, with the specified number of entries...</div><div class="ttdef"><b>Definition:</b> hala_gpu_engine.hpp:336</div></div>
<div class="ttc" id="group__HALABLAS1_html_ga48f8d9b686ef4a9cdb69897e3f22bbe5"><div class="ttname"><a href="group__HALABLAS1.html#ga48f8d9b686ef4a9cdb69897e3f22bbe5">hala::norm2</a></div><div class="ttdeci">auto norm2(int N, VectorLikeX const &amp;x, int incx)</div><div class="ttdoc">Wrapper to BLAS vector 2-norm. </div><div class="ttdef"><b>Definition:</b> hala_blas_1.hpp:105</div></div>
<div class="ttc" id="namespacehala_html_a15f4cd15d6f2fee76d37a6543539b6a4"><div class="ttname"><a href="namespacehala.html#a15f4cd15d6f2fee76d37a6543539b6a4">hala::get_cast</a></div><div class="ttdeci">T get_cast(U x)</div><div class="ttdoc">Cast a number into a new type, or copy if the type is the same. </div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:112</div></div>
<div class="ttc" id="group__HALABLAS2_html_ga9ff50eeb8bb1682349d7a68d2fdfe610"><div class="ttname"><a href="group__HALABLAS2.html#ga9ff50eeb8bb1682349d7a68d2fdfe610">hala::tbsv</a></div><div class="ttdeci">void tbsv(char uplo, char trans, char diag, int N, int k, const VectorLikeA &amp;A, int lda, VectorLikeX &amp;&amp;x, int incx)</div><div class="ttdoc">Wrapper to BLAS triangular matrix-vector solve xtbsv(). </div><div class="ttdef"><b>Definition:</b> hala_blas_2.hpp:313</div></div>
<div class="ttc" id="namespacehala_html"><div class="ttname"><a href="namespacehala.html">hala</a></div><div class="ttdoc">Master namespace encapsulating all HALA capabilities. </div><div class="ttdef"><b>Definition:</b> hala_core.hpp:69</div></div>
<div class="ttc" id="group__HALABLAS1_html_ga4f2f0c0b1c17c7a8ee5fe664fe0d652c"><div class="ttname"><a href="group__HALABLAS1.html#ga4f2f0c0b1c17c7a8ee5fe664fe0d652c">hala::iamax</a></div><div class="ttdeci">int iamax(int N, VectorLikeX const &amp;x, int incx)</div><div class="ttdoc">Wrapper to BLAS find index of largest vector entry, ixamax(). </div><div class="ttdef"><b>Definition:</b> hala_blas_1.hpp:177</div></div>
<div class="ttc" id="group__HALAWAXBLAS_html_ga27d50beba7026da717f6ebc52ac5ca6a"><div class="ttname"><a href="group__HALAWAXBLAS.html#ga27d50beba7026da717f6ebc52ac5ca6a">hala::vdivide</a></div><div class="ttdeci">void vdivide(VectorLikeX const &amp;x, VectorLikeY const &amp;y, VectorLikeZ &amp;&amp;z)</div><div class="ttdoc">Divide the two vectors component-wise. </div><div class="ttdef"><b>Definition:</b> hala_blas_extensions.hpp:139</div></div>
<div class="ttc" id="namespacehala_html_a98850706b7be2eb74266c994d1030a37"><div class="ttname"><a href="namespacehala.html#a98850706b7be2eb74266c994d1030a37">hala::hala_size</a></div><div class="ttdeci">size_t hala_size(IntA a, IntB b)</div><div class="ttdef"><b>Definition:</b> hala_core.hpp:134</div></div>
<div class="ttc" id="structhala_1_1gpu__engine_html_a09de76a77b7250e7884b298f5b35791f"><div class="ttname"><a href="structhala_1_1gpu__engine.html#a09de76a77b7250e7884b298f5b35791f">hala::gpu_engine::check_gpu</a></div><div class="ttdeci">void check_gpu(one_gpu_vec const &amp;x) const</div><div class="ttdoc">Assert that v1.gpu() matches this.gpu(), terminates the variadric recursion. </div><div class="ttdef"><b>Definition:</b> hala_gpu_engine.hpp:354</div></div>
<div class="ttc" id="group__HALACUSTOM_html_gab93c1d2ec9a0e8222f141d16c56a1b58"><div class="ttname"><a href="group__HALACUSTOM.html#gab93c1d2ec9a0e8222f141d16c56a1b58">hala::get_scalar_type</a></div><div class="ttdeci">typename define_type&lt; std::remove_reference_t&lt; VectorLike &gt; &gt;::value_type get_scalar_type</div><div class="ttdoc">Alias to the scalar type of a vector-like class. </div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:61</div></div>
<div class="ttc" id="group__HALACUSTOM_html_gacb23ab0a92ecead8007cf9aa8dc972db"><div class="ttname"><a href="group__HALACUSTOM.html#gacb23ab0a92ecead8007cf9aa8dc972db">hala::get_size</a></div><div class="ttdeci">size_t get_size(VectorLike const &amp;x)</div><div class="ttdoc">Returns the number of entries in the vector, if VectorLike does not have .size() method, then the template must be specialized. </div><div class="ttdef"><b>Definition:</b> hala_vector_defines.hpp:351</div></div>
<div class="ttc" id="namespacehala_1_1valid_html_ad23b9f8bdc1526aa44118fd70e427c27"><div class="ttname"><a href="namespacehala_1_1valid.html#ad23b9f8bdc1526aa44118fd70e427c27">hala::valid::default_ld</a></div><div class="ttdeci">void default_ld(int N, int &amp;lda)</div><div class="ttdoc">Sets default for lda, if lda is -1 then set it to N. </div><div class="ttdef"><b>Definition:</b> hala_input_checker.hpp:70</div></div>
<div class="ttc" id="group__HALAWAXBLAS_html_ga9d3d4f03da29c6cc6cf4b240e6a07c27"><div class="ttname"><a href="group__HALAWAXBLAS.html#ga9d3d4f03da29c6cc6cf4b240e6a07c27">hala::batch_scal</a></div><div class="ttdeci">void batch_scal(int batch_size, VectorLikeA const &amp;alpha, VectorLikeX &amp;&amp;x)</div><div class="ttdoc">Scales a batch of vectors by a set of constants. </div><div class="ttdef"><b>Definition:</b> hala_blas_extensions.hpp:114</div></div>
<div class="ttc" id="namespacehala_html_ac5f569cff6185ec959911b50370e6af9"><div class="ttname"><a href="namespacehala.html#ac5f569cff6185ec959911b50370e6af9">hala::check_size</a></div><div class="ttdeci">bool check_size(VectorLike &amp;x, SizeType required_size)</div><div class="ttdoc">Return true if get_size(x) is no less than required_size, also calls static cast to size_t to avoid e...</div><div class="ttdef"><b>Definition:</b> hala_types_checker.hpp:119</div></div>
<div class="ttc" id="structhala_1_1gpu__engine_html"><div class="ttname"><a href="structhala_1_1gpu__engine.html">hala::gpu_engine</a></div><div class="ttdoc">Core engine class, deals with handles and data transfer. </div><div class="ttdef"><b>Definition:</b> hala_gpu_engine.hpp:47</div></div>
<div class="ttc" id="structhala_1_1gpu__pntr_html"><div class="ttname"><a href="structhala_1_1gpu__pntr.html">hala::gpu_pntr</a></div><div class="ttdef"><b>Definition:</b> hala_gpu_engine.hpp:470</div></div>
<div class="ttc" id="group__HALAWAXBLAS_html_ga329f68a7f474c1502564d9afe5c6c729"><div class="ttname"><a href="group__HALAWAXBLAS.html#ga329f68a7f474c1502564d9afe5c6c729">hala::batch_max_norm2</a></div><div class="ttdeci">auto batch_max_norm2(cengine const &amp;engine, int batch_size, VectorLike const &amp;x)</div><div class="ttdoc">Returns the norm of the largest vector in a batch. </div><div class="ttdef"><b>Definition:</b> hala_blas_extensions.hpp:354</div></div>
<div class="ttc" id="group__HALABLAS2_html_ga925bf0c14261ed419bb931e85658f6eb"><div class="ttname"><a href="group__HALABLAS2.html#ga925bf0c14261ed419bb931e85658f6eb">hala::gemv</a></div><div class="ttdeci">void gemv(char trans, int M, int N, FSa alpha, const VectorLikeA &amp;A, int lda, const VectorLikeX &amp;x, int incx, FSb beta, VectorLikeY &amp;&amp;y, int incy)</div><div class="ttdoc">Wrapper to BLAS general matrix-vector multiply xgemv(). </div><div class="ttdef"><b>Definition:</b> hala_blas_2.hpp:57</div></div>
<div class="ttc" id="group__HALAGPUBLAS0_html_ga913ed4bb219b279b396fe0a9ad5986bd"><div class="ttname"><a href="group__HALAGPUBLAS0.html#ga913ed4bb219b279b396fe0a9ad5986bd">hala::dgmm</a></div><div class="ttdeci">void dgmm(gpu_engine const &amp;engine, char side, int M, int N, VectorLikeA const &amp;A, int lda, VectorLikeB const &amp;x, int incx, VectorLikeC &amp;&amp;C, int ldc)</div><div class="ttdoc">Wrapper to GPU-BLAS matrix addition Xdgmm(). </div><div class="ttdef"><b>Definition:</b> hala_gpu_blas0.hpp:108</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.15-->
<!-- start footer part -->
<!-- <div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
<!--  <ul>
    <li class="navelem"><a class="el" href="dir_7156e66327c057925328a1f19fe47a9c.html">wax</a></li><li class="navelem"><b>hala_blas_extensions.hpp</b></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div> -->
</body>
</html>
